{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArff(filename):\n",
    "    with open ('./UCI-Data/'+filename+'.arff', 'r') as f:\n",
    "        # split lines, remove ones with comments\n",
    "        lines = [line.lower() for line in f.read().split('\\n') if not line.startswith('%')]\n",
    "        \n",
    "    # remove empty lines\n",
    "    lines = [line for line in lines if line != '']\n",
    "    \n",
    "    columns = []\n",
    "    data = []\n",
    "    for index, line in enumerate(lines):\n",
    "        if line.startswith('@attribute'):\n",
    "            columns.append(line)\n",
    "            \n",
    "        if line.startswith('@data'):\n",
    "            # get the rest of the lines excluding the one that says @data\n",
    "            data = lines[index+1:]\n",
    "            break\n",
    "            \n",
    "    # clean column names -- '@attribute colname  \\t\\t\\t{a, b, ...}'\n",
    "    cleaned_columns = [c[11:c.index('real')].strip() for c in columns[:-1]]\n",
    "    \n",
    "    # ** change for real values. skip last column and parse differently\n",
    "    class_val = columns[-1]\n",
    "    cleaned_columns.append(class_val[11:class_val.index('{')].strip())\n",
    "    \n",
    "    # clean and split data\n",
    "    cleaned_data = [d.replace(', ', ',').split(',') for d in data]\n",
    "    \n",
    "    # create dataframe\n",
    "    return pd.DataFrame(cleaned_data, columns = cleaned_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    ys = df.iloc[:,-1]\n",
    "    ys = ys.values\n",
    "    \n",
    "    # change xs to 2d numpy array -- convert strings to floats\n",
    "    xs = df.iloc[:,:-1].astype(float)\n",
    "    xs = xs.values\n",
    "    \n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = preprocess_data(readArff(\"iris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = len(set(y))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids(X, k):\n",
    "    \"\"\"\n",
    "    Returns a matrix representing k randomly chosen instances for the initial centroids\n",
    "    \"\"\"\n",
    "    n_instances, n_features = np.shape(X)\n",
    "    centroids = np.zeros((k, n_features))\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Note: should we be checking to make sure they aren't the same?\n",
    "        # feels like yes but i dont want to deal with that now lol\n",
    "        centroids[i] = X[np.random.choice(range(n_instances))]\n",
    "        \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7, 2.6, 3.5, 1. ],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5.7, 2.8, 4.1, 1.3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = initialize_centroids(X,k)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" Calculates the euclidean distance between two points \"\"\"\n",
    "    assert np.size(x1) == np.size(x2)\n",
    "\n",
    "    # Squared distance between each coordinate\n",
    "    distances = np.square(x1 - x2)\n",
    "    return np.sqrt(sum(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_centroid(instance, centroids):\n",
    "    \"\"\"\n",
    "    Helper method for create_clusters.\n",
    "    \n",
    "    Returns the index of the closest centroid for a given instance\n",
    "    Distance measured using euclidean_distance\n",
    "    \"\"\"\n",
    "    closest = -1\n",
    "    closest_dist = float('inf')\n",
    "    for i, c in enumerate(centroids):\n",
    "        dist = euclidean_distance(instance, c)\n",
    "        if dist < closest_dist:\n",
    "            closest_dist = dist\n",
    "            closest = i\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(X, k, centroids):\n",
    "    \"\"\"\n",
    "    Returns a list of k-lists, each containing the indices of instances that are closest to the centroid\n",
    "    \n",
    "    ** stop storing the instances themselves it wastes space, just save instances\n",
    "    \"\"\"\n",
    "    n_instances, n_features = np.shape(X)\n",
    "    clusters = [[] for _ in range(k)]     # create clusters of centroids\n",
    "    \n",
    "    for i, x_i in enumerate(X):\n",
    "        centroid_idx = find_nearest_centroid(x_i, centroids)\n",
    "        clusters[centroid_idx].append(i)\n",
    "    \n",
    "    assert sum([len(c) for c in clusters]) == n_instances # sanity check\n",
    "    \n",
    "    return clusters\n",
    "    # turn list of np.arrays into list of 2D arrays\n",
    "#     return [np.reshape(c, newshape = (len(c), n_features)) for c in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = create_clusters(X, k, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each cluster 1...k, calculate new centroid = mean of all points assigned to that cluster\n",
    "def update_centroids(X, k, clusters):\n",
    "    n_features = np.shape(X)[1]\n",
    "    new_centroids = np.zeros((k, n_features))\n",
    "    \n",
    "    for i, clstr in enumerate(clusters):\n",
    "        centroid = np.mean(X[clstr], axis=0)\n",
    "        new_centroids[i] = centroid\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33333333, -0.18888889,  0.02222222,  0.05555556],\n",
       "       [-0.094     , -0.282     , -0.036     , -0.156     ],\n",
       "       [ 0.65054945,  0.11758242,  0.94285714,  0.43736264]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_centroids = update_centroids(X, k, clusters)\n",
    "delta = new_centroids - centroids\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_groups(X, clusters):\n",
    "    \"\"\"\n",
    "    Return a vector of len n_instances that correspond to 0, 1, ... k \n",
    "    that corresponds to the cluster each instance was in at the end of training\n",
    "    \"\"\"\n",
    "    preds = np.zeros(np.shape(X)[0])\n",
    "    for i, c in enumerate(clusters):\n",
    "        for instance in c:\n",
    "            preds[instance] = i\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predition_map(X, k, clusters):\n",
    "    \"\"\"\n",
    "    *Note:* uses true y value -- put in seperate function of generating predictions because of this\n",
    "    This function returns a dict from our cluster numbers 0, 1, ... k -> actual class values\n",
    "    \"\"\"\n",
    "    # map clusters to classes\n",
    "    result = {k : 0 for k in range(k)}\n",
    "    for i, c in enumerate(clusters):\n",
    "        class_map = {class_val : 0 for class_val in y} # count number of each class per cluster to find most popular\n",
    "        \n",
    "        for instance in c:\n",
    "            val = y[instance]\n",
    "            class_map[val] = class_map.get(val, 0) + 1 # update counts\n",
    "            \n",
    "        most_popular_class = max(class_map, key=class_map.get)\n",
    "        result[i] = most_popular_class\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "def predict(X):\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        clusters = create_clusters(X, k, centroids)\n",
    "        \n",
    "        prev_centroids = centroids\n",
    "        \n",
    "        centroids = update_centroids(X, k, clusters)\n",
    "       \n",
    "        # If no centroids have changed => convergence\n",
    "        delta = centroids - prev_centroids\n",
    "        if np.all((delta == 0)):\n",
    "            break\n",
    "    preds = generate_predictions(X, clusters)\n",
    "    pred_map = generate_predition_map(X, k, clusters)\n",
    "    results = [pred_map[p] for p in preds]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11333333333333329"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - accuracy_score(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
